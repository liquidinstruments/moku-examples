{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Anomaly Detection example\n",
    "\n",
    "An autoencoder is a type of neural network that learns to reconstruct its input, making it useful for anomaly detection in signals. If a given input contains an unusual pattern that the network hasn't learned well, the reconstruction error will be high for that part, identifying the anomaly. \n",
    "\n",
    "In this example, we will train an autoencoder to model a known periodic signal, which can flag anomalies via a large reconstruction error. We will use a Moku device to capture the signal data, then train a neural network model that can later be deployed on the Moku for real-time anomaly detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Optional: if running on a fresh environment like Google Colab, install or upgrade the Moku API library (with Neural Network support) before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this if Moku library is not installed\n",
    "# !pip install -U \"moku[neuralnetwork]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "First, we import the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Next, we import the Moku instrument classes we need, as well as the neural network model utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moku.instruments import MultiInstrument, Oscilloscope\n",
    "\n",
    "try:\n",
    "    from moku.nn import LinnModel, save_linn\n",
    "except ImportError:\n",
    "    print(\"Moku library is not installed. If running in an online notebook, install it with the pip command above.\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We'll define some helper functions for later use, particularly ffor formatting and data I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sampling_rate(rate):\n",
    "    \"\"\"Format a sampling rate in Hz to kHz or MHz if applicable.\"\"\"\n",
    "    if rate >= 1e6:\n",
    "        return f\"{rate/1e6:.2f} MHz\"\n",
    "    elif rate >= 1e3:\n",
    "        return f\"{rate/1e3:.2f} kHz\"\n",
    "    else:\n",
    "        return f\"{rate:.2f} Hz\"\n",
    "\n",
    "def save_data_to_csv(data_points, window_size, filename):\n",
    "    \"\"\"Save 1D data points into CSV file, splitting into fixed-size windows per row.\"\"\"\n",
    "    # Ensure all values are floats\n",
    "    data_points = [float(x) for x in data_points]\n",
    "\n",
    "    # Split data into consecutive windows of length window_size\n",
    "    windows = []\n",
    "    num_points = len(data_points)\n",
    "    i = 0\n",
    "    while i + window_size <= num_points:\n",
    "        windows.append(data_points[i:i + window_size])\n",
    "        i += window_size\n",
    "    # Handle the last partial window (pad or adjust start to full length)\n",
    "    if i < num_points:\n",
    "        start = max(0, num_points - window_size)\n",
    "        windows.append(data_points[start:num_points])\n",
    "\n",
    "    # Determine next ID for data frames by counting existing rows in file\n",
    "    file_exists = os.path.exists(filename)\n",
    "    next_id = 0\n",
    "    if file_exists:\n",
    "        with open(filename, 'r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader, None)  # skip header\n",
    "            next_id = sum(1 for _ in reader)\n",
    "\n",
    "    # Append new data windows to the CSV\n",
    "    with open(filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['id', 'data'])  # write header if new file\n",
    "        for w in windows:\n",
    "            writer.writerow([next_id, ';'.join(f\"{x:.6f}\" for x in w)])\n",
    "            next_id += 1\n",
    "\n",
    "def load_data_from_csv(filename):\n",
    "    \"\"\"Load data windows from the CSV file back into a list of lists of float values.\"\"\"\n",
    "    data_windows = []\n",
    "    with open(filename, 'r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader, None)  # skip header if present\n",
    "        for row in reader:\n",
    "            if len(row) < 2:\n",
    "                continue  # skip malformed rows\n",
    "            # Each row's second column is a ';'-separated list of values\n",
    "            values = [float(x) for x in row[1].split(';')]\n",
    "            data_windows.append(values)\n",
    "    return data_windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We can see the available Moku devices, using the Moku CLI through the command line as a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mokucli list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The above command should output a list of connected Moku devices with their name, serial, IP, etc. Ensure your Moku device is listed and reachable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 2. Set up the Oscilloscope for data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "First, set up the folder structure for organizaing output data and define the filename for captured data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output folder and base filename\n",
    "output_folder = \"AD_dataset/\"\n",
    "output_filename = \"data_training\"\n",
    "\n",
    "# Generate a unique filename with timestamp to avoid overwriting\n",
    "timestamp = str(time.time()).split(\".\")[-1]\n",
    "output_filename = f\"{output_folder}{output_filename}_{timestamp}.csv\"\n",
    "print(f\"Data will be saved in the file: {output_filename}\" )\n",
    "\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"Folder created: {output_folder}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Now, deploy the Oscilloscope instrument on your Moku. Connect to your Moku hardware by initializing a MultiInstrument with the device's IP address. In this example we use a Moku:Pro, and so we set platform_id to 4. \n",
    "\n",
    "Connections in Multi-Instrument Mode are defined by an array of dictionaries. In this example, we route the signal from the analog frontend (Input 1) to the first input channel of the Oscilloscope. We also define the coupling, attenuation, and impedance of the frontend.\n",
    "\n",
    "Note: Replace '10.1.119.245' with your Moku’s IP address (and adjust platform_id if using a different Moku model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Moku device and deploy an Oscilloscope instrument\n",
    "mim = MultiInstrument('10.1.119.245', force_connect=True, platform_id=4)\n",
    "osc = mim.set_instrument(4, Oscilloscope)\n",
    "\n",
    "connections = [dict(source=\"Input1\", destination=\"Slot4InA\")]\n",
    "mim.set_connections(connections=connections)\n",
    "mim.set_frontend(channel=1, impedance=\"50Ohm\", coupling=\"DC\", attenuation=\"-20dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Configure the Oscilloscope acquisition parameters, including number of samples and how many frames of data to capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquisition parameters\n",
    "window_size = 100        # number of samples per frame (window length)\n",
    "n_frames = 100           # number of frames to capture for dataset\n",
    "t1 = 0.0                 # start time (seconds)\n",
    "t2 = 0.1                 # end time (seconds) for each frame\n",
    "duration = t2 - t1\n",
    "\n",
    "# Set the oscilloscope timebase for each frame capture\n",
    "osc.set_timebase(t1, t2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Now collect the data frames from the Oscilloscope via the get_data command. We will capture n_frames frames of channel data and save them to the CSV file defined above. The code below reads data from the Oscilloscope, uses our save_data_to_csv function to append each frame to the file, and prints progress as it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_frames), desc=\"Saving data\"):\n",
    "    data = osc.get_data()\n",
    "    save_data_to_csv(data[\"ch1\"], window_size, filename=output_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Now let's verify the sampling rate and examine one captured frame of data as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display the sampling rate based on captured data\n",
    "sampling_rate = osc.get_samplerate()\n",
    "print(\"Sampling rate:\", format_sampling_rate(osc.get_samplerate()[\"sample_rate\"]))\n",
    "\n",
    "# Plot an example frame of the captured data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(data[\"time\"], data[\"ch1\"])\n",
    "plt.title(\"Example Captured Waveform (one frame)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Voltage\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Print the first 100 datapoints of the frame. This 100-datapolint signal is an example of the training data that will be used for training the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example frame of the training data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(data[\"time\"][:100], data[\"ch1\"][:100])\n",
    "plt.title(\"Example Training Data (one frame)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Voltage\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 3. Compose the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Now that data has been collected, we load it from the CSV and split it into separate training and testing sets. We will use a simple 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved frames from CSV\n",
    "data = load_data_from_csv(output_filename)\n",
    "\n",
    "# Split into training and testing datasets (80% train, 20% test)\n",
    "split_index = int(len(data) * 0.8)\n",
    "full_training_dataset = data[:split_index]\n",
    "full_testing_dataset = data[split_index:]\n",
    "\n",
    "print(f\"N. of frames in the training dataset: {len(full_training_dataset)}\")\n",
    "print(f\"N. of frames in the testing dataset: {len(full_testing_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## 4. Define the model and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Instantiate the Moku Neural Network model object using LinnModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_mod = LinnModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Set up an early stopping point for training to avoid overfitting. This will truncate the training if the validation loss doesn’t improve for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_config = {\n",
    "    'patience': 10,            # allow 10 epochs without improvement\n",
    "    'restore_best_weights': True,\n",
    "    'monitor':\"val_loss\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Now, prepare the model definition. This is an autoencoder, a small fully-connected neural network that compresses and then reconstructs the input signal. The model will output the same number of samples as the input frame (100). We disable automatic scaling of data (scale=False) because we want to work with raw values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = len(full_training_dataset[0])\n",
    "print(f\"frame length/input dimension: {frame_length}\")\n",
    "\n",
    "# Configure the model inputs/outputs (autoencoder: outputs = inputs)\n",
    "quant_mod.set_training_data(training_inputs=full_training_dataset,\n",
    "                             training_outputs=full_training_dataset,\n",
    "                             scale=False)\n",
    "\n",
    "# Define a simple autoencoder architecture: \n",
    "#  - encoder layers with 64, 32, 16 neurons (tanh activations)\n",
    "#  - final decoder layer with 'frame_length' neurons (linear activation)\n",
    "model_definition = [\n",
    "    (64, 'tanh'),\n",
    "    (32, 'tanh'),\n",
    "    (16, 'tanh'),\n",
    "    (frame_length, 'linear')\n",
    "]\n",
    "\n",
    "# Build the model\n",
    "quant_mod.construct_model(model_definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Now train the model on the training dataset we defined earlier. We include a 10% validation split (which comes from the training set itself) for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = quant_mod.fit_model(\n",
    "    epochs=250,\n",
    "    es_config=early_stopping_config,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Plot the training and validation loss history to confirm convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train loss', 'val loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "In this case, the final loss values are extremely low, indicating the autoencoder learned to reconstruct our sine wave signals very accurately. Next, save the quantized model to a file using save_linn. This will produce a .linn file that can be deployed to the Moku device’s FPGA for real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"AD_model.linn\"\n",
    "# Create a time-base array for mapping (same length as frame)\n",
    "T = np.linspace(-1, 1, frame_length)\n",
    "# Save the trained model to file\n",
    "save_linn(quant_mod, input_channels=1, output_channels=1,\n",
    "          file_name=model_filename, output_mapping=[T.size-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## 5. Testing the model - reconstruct the training dataset\n",
    "Now that the model is trained, let’s verify how well it performs on data it saw during training. We feed the entire training dataset through the model to get reconstructed signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_dataset_np = np.array(full_training_dataset)\n",
    "reconstructions = quant_mod.predict(full_training_dataset_np, scale=False, unscale_output=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "The reconstructions array contains the model output for each input frame. For a well-trained autoencoder, these reconstructed frames should closely match the originals. As a quick visual check, we can pick one training frame and compare it with its reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 0  # for example, take the first training frame\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(full_training_dataset[frame_id], label='Original')\n",
    "plt.plot(reconstructions[frame_id], label='Reconstruction', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Original vs Reconstructed Signal')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## 6. Testing the model on the unseen dataset\n",
    "Now we evaluate the autoencoder on the frames the model has not seen before. We expect the model to reconstruct normal frames well, but frames with anomalies (such as glitches) should yield a larger reconstruction error since the model was not trained on that behavior. \n",
    "\n",
    "First, generate reconstructions for all test frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_testing_dataset_np = np.array(full_testing_dataset)\n",
    "reconstructions_test = quant_mod.predict(full_testing_dataset_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "To illustrate the model’s performance, let's compare the output on a specific test frame that contains a known anomaly versus a test frame that is normal. Suppose we know that frame index 147 in our dataset contains a glitch, and frame 146 is a normal frame for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id_anomaly_test = 31\n",
    "frame_id_normal_test = 146 \n",
    "\n",
    "# Plot original vs reconstructed for the anomalous frame\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(full_testing_dataset[frame_id_anomaly_test], label='Original')\n",
    "plt.plot(reconstructions_test[frame_id_anomaly_test], label='Reconstruction', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Original vs Reconstructed Signal (Anomalous frame)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot original vs reconstructed for a normal frame\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(full_testing_dataset[frame_id_normal_test], label='Original')\n",
    "plt.plot(reconstructions_test[frame_id_normal_test], label='Reconstruction', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Original vs Reconstructed Signal (Normal frame)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "To detect the anomaly quantitatively, we need to examine the reconstruction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## 7. Extract the reconstruction error\n",
    "Calculate the element-wise error between original and reconstructed signals for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = np.array(full_testing_dataset)\n",
    "reconstructed = np.array(reconstructions_test)\n",
    "\n",
    "# --- Error calculations ---\n",
    "# Absolute error for each sample\n",
    "absolute_error = np.abs(original - reconstructed)\n",
    "# Squared error for each sample\n",
    "squared_error = (original - reconstructed) ** 2\n",
    "\n",
    "# Summed error per frame (could be used as an anomaly score per frame)\n",
    "absolute_error_per_frame = absolute_error.sum(axis=1)\n",
    "squared_error_per_frame = squared_error.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Now, compare the error profiles of the previously chosen anomalous frame with the normal frame. We expect the frame with the glitch to show a spike in error at the glitch location, whereas the normal frame’s error should remain near zero across all sample indices. For example, we can plot the squared error for both frames on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(squared_error[frame_id_anomaly_test], label='Frame with anomaly', color='orange')\n",
    "plt.plot(squared_error[frame_id_normal_test], label='Normal Frame', color='blue')\n",
    "plt.title('Reconstruction Squared Error (per sample)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "In the plot above, the anomalous frame (orange curve) has several spikes in error, whereas the normal frame error (blue line) is essentially flat at zero. This indicates the autoencoder was unable to reconstruct those glitch points, as expected. \n",
    "\n",
    "We can further quantify this by applying a numerical threshold. In this example we'll set this threshold at an absolute error of 0.0002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0002\n",
    "\n",
    "# Find indices in the anomaly frame where absolute error > threshold\n",
    "indices_anom = [i for i, v in enumerate(squared_error[frame_id_anomaly_test]) if v > threshold]\n",
    "values_anom = [squared_error[frame_id_anomaly_test][i] for i in indices_anom]\n",
    "print(\"Frame with anomaly\")\n",
    "print(\"Indices of values > threshold:\", indices_anom)\n",
    "print(\"Corresponding values:\", values_anom)\n",
    "\n",
    "print(\"—\" * 70)\n",
    "\n",
    "# Find indices in the normal frame where absolute error > threshold\n",
    "indices_norm = [i for i, v in enumerate(squared_error[frame_id_normal_test]) if v > threshold]\n",
    "values_norm = [squared_error[frame_id_normal_test][i] for i in indices_norm]\n",
    "print(\"Normal frame\")\n",
    "print(\"Indices of values > threshold:\", indices_norm)\n",
    "print(\"Corresponding values:\", values_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "As expected, the anomalous frame has a few samples where the reconstruction error exceeds the threshold, while the normal frame has none. These correspond to the glitch points in the signal. \n",
    "\n",
    "To further reduce false detections, we experimented with using higher-order error metrics. For example, defining a \"focal MSE loss\" (squared error raised to a power >1) can down-weight small differences and emphasize larger errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_mse_loss(prediction, target, gamma=2.5):\n",
    "    error = prediction - target\n",
    "    squared_error = error ** 2\n",
    "    return squared_error ** gamma\n",
    "\n",
    "# Compute focal loss for each sample\n",
    "focal_loss = focal_mse_loss(reconstructed, original)\n",
    "focal_loss_per_frame = focal_loss.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(focal_loss[frame_id_anomaly_test], label='Frame with anomaly', color='orange')\n",
    "plt.plot(focal_loss[frame_id_normal_test], label='Normal Frame', color='blue')\n",
    "plt.title('Reconstruction Focal Loss (per sample)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e-9\n",
    "\n",
    "# Find indices where value > threshold\n",
    "\n",
    "# Frame with Anomaly\n",
    "indices = [i for i, v in enumerate(focal_loss[frame_id_anomaly_test]) if v > threshold]\n",
    "\n",
    "# Print results\n",
    "print(\"Frame with anomaly\")\n",
    "print(\"Indices of values > threshold:\", indices)\n",
    "print(\"Corresponding values:\", [focal_loss[frame_id_anomaly_test][i] for i in indices])\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# Normal with Anomaly\n",
    "indices = [i for i, v in enumerate(focal_loss[frame_id_normal_test]) if v > threshold]\n",
    "\n",
    "# Print results\n",
    "print(\"Normal frame\")\n",
    "print(\"Indices of values > threshold:\", indices)\n",
    "print(\"Corresponding values:\", [focal_loss[frame_id_normal_test][i] for i in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Overall, the autoencoder approach successfully learned the normal signal behavior and flagged the anomaly via reconstruction error. In summary:\n",
    "- Normal frames: Reconstructed almost perfectly, with near-zero error across all samples.\n",
    "- Anomalous frame: Reconstruction deviates at the glitch points, yielding measurable error spikes.\n",
    "\n",
    "This demonstrates how an FPGA-deployable autoencoder, trained via Moku’s Python API, can perform real-time anomaly detection on signal data. The .linn model file saved can be loaded onto the Moku device to monitor incoming signals and detect anomalies based on the model’s reconstruction error in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## Deploy on Moku\n",
    "\n",
    "To test the model and deploy the anomaly detection feature, open your Moku on Multi-Instrument Mode. \n",
    "\n",
    "Place the Neural Network instrument into Slot 1 and load the .linn file. Route the signal source to the Neural Network input (e.g., the output of a Waveform Generator or an external signal source), and enable the output. The Neural Network will output the reconstructed signal in real time.\n",
    "\n",
    "You can then place an Oscilloscope in another slot to visualize both the original and reconstructed signals simultaneously. You should see that the reconstructed signal closely tracks the original except when anomalies occur, as we observed in the offline test. The reconstructed signal might be slightly delayed relative to the original due to some finite latency. One strategy to compensate for this is to deploy a second neural network configured as an identity network (a network that simply outputs its input) in another slot to delay the original signal by the same amount. By aligning the phase in this way, you can directly compare the original and autoencoder output signals.\n",
    "\n",
    "To automate anomaly detection, you can measure the difference between the original and reconstructed signals on the Moku. For example, you could use a custom Moku Cloud Compile (MCC) module that outputs the squared error. This error signal will spike when the original signal deviates from the learned normal pattern, which can be detected using a threshold trigger on the Oscilloscope or Data Logger. \n",
    "\n",
    "![MiM](tutorial_1.png)\n",
    "\n",
    "![Reconstruction error in Channel C](tutorial_2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
